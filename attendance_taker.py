# -*- coding: utf-8 -*-
"""Attendance taker

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b9O5KYsYeUNgGe7uL9oMUBDN0rSpybvF
"""

#!pip install face_recognition

import cv2
import numpy as np
import face_recognition
import dlib
#from google.colab.patches import cv2_imshow
#use cv2.imshow is you are not using colab

import os



def _mark_attendance(path):#path is a folder containing images to be trained
  images = []
  classNames = []
  myList = os.listdir(path)
  print(myList)#prints images in folder
  for cls in myList:
    current_image = cv2.imread(f'{path}/{cls}')
    images.append(current_image)
    classNames.append(os.path.splitext(cls)[0])#revoming .jpg
  print(classNames)
  def find_encodings(images):
      encode_list = []
      for img in images:
        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
        encode = face_recognition.face_encodings(img)[0]
        encode_list.append(encode)
        print('Encoding Complete')
      return encode_list

  encodelist = find_encodings(images)
  from datetime import datetime
  def _mark_attendance(name):
    #you can create a new csv file
    with open('Attendance.csv','r+') as f:
      myDataList = f.readlines()
      print(myDataList)
      newlist = []
      for line in myDataList:
        entry = line.split(',')
        newlist.append(entry[0])
        if name not in newlist:
          now = datetime.now()
          dfString = now.strftime('%H:%M:%S')
          f.writelines(f'\n{name} {dfString}')
  #initializing videocam
  cap = cv2.VideoCapture(0)
  while True:
    success, img = cap.read()
    #reducing size
    imgSmall = cv2.resize(img,(0,0),None,0.25,0.25)
    imgSmall = cv2.cvtColor(imgSmall, cv2.COLOR_BGR2RGB)
    face_location_current_frame = face_recognition.face_locations(imgSmall)
    encode_current_frame = face_recognition.face_encodings(img, face_location_current_frame)

    for encode_face, face_loc in zip(encode_current_frame,face_location_current_frame):
      matches = face_recognition.compare_faces(encodelist,encode_face)
      face_distance = face_recognition.face_distance(encodelist, encode_name)
      print(face_distance)
      matchIndex = np.argmin(face_distance)
    
    #printing match name
    if matches[matchIndex]:
      name = classNames[matchIndex].upper()
      print(name)
      y1,x2,y2,x1 = face_loc
      y1,x2,y2,x1 = y1*4,x2*4,y2*4,x1*4
      cv2.rectangle(img, (x1,y1),(x2,y2),(0,255,0),2)
      cv2.rectangle(img, (x1,y1-35),(x2,y2),(0,255,0),cv2.FILLED)
      cv2.putText(name,(x1+6,y1-6), cv2.FONT_HERSHEY_COMPLEX,1,(225,225,225),2)













